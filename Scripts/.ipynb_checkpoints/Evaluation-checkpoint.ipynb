{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lt0LgbVSdED",
    "outputId": "ebbc4f85-47b6-4045-d881-43747c9e1747"
   },
   "outputs": [],
   "source": [
    "!pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KbvewVf1QCpT",
    "outputId": "b6b3d744-6b7c-4684-d494-ded54fd02cc9"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_speeches_dict = {'101112641': [\"I thank my colleague. the senior Senator from Alaska. and I thank the Chair. As I think my colleagues have observed. the concern expressed by the senior Senator is not a concern he shares alone. I find It utterly amazing that this agricultural bill there should suddenly be subject to a proposal on fisheries.\", \"Mr. Leader. for those of us who are on the west coast. Washington. Oregon. Alaska. and Hawaii. as he contemplates the schedule for coming back on Tuesday. would he give some consideration to votes on Tuesday. if he so desires. to coincide with our ability to get back. we can all get back prior to 4:15. but unless we leave on Monday. it is impossible to be here early.\", \"I commend him for his cooperation and his working with the chairman to the point where we are today. Other Members as well. including Senator MErZENBAUM. Thank you.\"],\n",
    "                     '101109290': [\"Mr. Chairman. I yield 4 minutes to the gentleman from Louisiana .\", \"Mr. Chairman. I ask unanimous consent that the amendment in the nature of a substitute made in order as an original text by the rule be printed in the REcoRD and open to amendment at any point.\", \"Mr. Chairman. I offer amendments and I ask unanimous consent that they be considered en bloc.\"],\n",
    "                     '104118220': [\"We have touched on the fact that these cuts will be devastating for Medicare recipients.\", \"If the gentleman will yield. when we are talking about education. we are not just talking about student loans.\", \"Here you have schools all over America and in the State of Vermont working extremely hard to keep kids off of drugs.\"]}\n",
    "\n",
    "generated_speeches_dict = {'101112641': [\"I thank my colleague, the hon. member for Saint-Mauriceâ€”Champlain, for the opportunity to speak to Bill C-218, An Act to amend the Criminal Code and the Controlled Drugs and Substances Act (sentencing for offences involving trafficking in persons).\", \"Mr. Leader. for those of us who have been here a long time, this is not the first time that we have had to deal with this issue. We have dealt with it in the past, and we will deal with it in the future.\", \"I commend him for his cooperation and his willingness to work with us.\"],\n",
    "                      '101109290': [\"Mr. Chairman. I yield myself such time as I may consume.\", \"Mr. Chairman. I ask unanimous consent that all Members may have 5 legislative days in which to revise and extend their remarks and to include extraneous material on H.R. 2499, as amended.\", 'Mr. Chairman. I offer an amendment to H.R. 1011.\\nThe amendment is as follows:\\n Page 2, line 1, strike out the word \"the\" and insert in lieu thereof the word \"that\".'],\n",
    "                      '104118220': [\"We have touched on this subject before.\", \"If the gentleman will permit me to say a few words, I shall be glad to do so.\", \"Here you have schools, colleges, and universities.\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the texts (optional but recommended)\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert text to lowercase\n",
    "    text = \" \".join(nltk.word_tokenize(text))  # Tokenize text into words\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F-_tpvlBP7o0",
    "outputId": "4ff6073f-e0de-475e-aed1-16732b5ce41b"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def calculate_rouge_bleu_score(id):\n",
    "    \n",
    "    # Sample speeches (replace these with your actual speeches)\n",
    "    actual_speeches = actual_speeches_dict[id]\n",
    "\n",
    "    generated_speeches = generated_speeches_dict[id]\n",
    "\n",
    "    actual_speeches = [preprocess_text(text) for text in actual_speeches]\n",
    "    generated_speeches = [preprocess_text(text) for text in generated_speeches]\n",
    "\n",
    "    # Calculate BLEU score for each generated speech compared to its corresponding actual speech\n",
    "    bleu_scores = []\n",
    "    for actual_speech, generated_speech in zip(actual_speeches, generated_speeches):\n",
    "        bleu_score = sentence_bleu([actual_speech.split()], generated_speech.split())\n",
    "        bleu_scores.append(bleu_score)\n",
    "\n",
    "    # Create a RougeScorer instance\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "    # Calculate ROUGE scores for each generated speech compared to its corresponding actual speech\n",
    "    rouge_scores = []\n",
    "    for actual_speech, generated_speech in zip(actual_speeches, generated_speeches):\n",
    "        scores = scorer.score(generated_speech, actual_speech)\n",
    "        rouge_scores.append(scores)\n",
    "\n",
    "    # Print the BLEU scores\n",
    "    print(\"BLEU Scores:\")\n",
    "    for i, bleu_score in enumerate(bleu_scores, 1):\n",
    "        print(f\"Speech {i}: {bleu_score}\")\n",
    "\n",
    "    # Print the ROUGE scores\n",
    "    for i, scores in enumerate(rouge_scores, 1):\n",
    "        print(f\"ROUGE Scores for speech {i}:\")\n",
    "        print(f\"ROUGE-1: {scores['rouge1'].fmeasure}\")\n",
    "        print(f\"ROUGE-2: {scores['rouge2'].fmeasure}\")\n",
    "        print(f\"ROUGE-L: {scores['rougeL'].fmeasure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "id": "h-nUw58XWllD",
    "outputId": "a6547c45-b925-42dd-b7a1-648f41303b64"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from transformers import BartTokenizer, BartModel\n",
    "import torch\n",
    "\n",
    "def create_embeddings_and_calculate_cos_sim(id):\n",
    "    # Sample speeches (replace these with your actual speeches)\n",
    "    actual_speeches = actual_speeches_dict[id]\n",
    "\n",
    "    generated_speeches = generated_speeches_dict[id]\n",
    "\n",
    "    # Download 'punkt' tokenizer data (if not already downloaded)\n",
    "    nltk.download('punkt')\n",
    "\n",
    "    # Preprocess the actual and generated speeches\n",
    "    actual_speeches = [preprocess_text(text) for text in actual_speeches]\n",
    "    generated_speeches = [preprocess_text(text) for text in generated_speeches]\n",
    "\n",
    "    # Load BART tokenizer and model\n",
    "    tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "    model = BartModel.from_pretrained('facebook/bart-large')\n",
    "\n",
    "    # Function to create embeddings from text using BART\n",
    "    def create_bart_embeddings(text):\n",
    "        input_ids = tokenizer.encode(text, return_tensors=\"pt\", add_special_tokens=True)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids)\n",
    "        embeddings = output.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "        return embeddings\n",
    "\n",
    "    # Create embeddings for actual speeches and generated speeches\n",
    "    actual_embeddings = [create_bart_embeddings(text) for text in actual_speeches]\n",
    "    generated_embeddings = [create_bart_embeddings(text) for text in generated_speeches]\n",
    "\n",
    "    # Remove None embeddings (if any)\n",
    "    actual_embeddings = [embed for embed in actual_embeddings if embed is not None]\n",
    "    generated_embeddings = [embed for embed in generated_embeddings if embed is not None]\n",
    "\n",
    "    # Calculate cosine similarity between embeddings\n",
    "    cosine_similarity = np.dot(actual_embeddings, np.array(generated_embeddings).T) / (\n",
    "        np.linalg.norm(actual_embeddings, axis=1)[:, None] * np.linalg.norm(np.array(generated_embeddings), axis=1)\n",
    "    )\n",
    "\n",
    "    # Print cosine similarity for each speech pair\n",
    "    print(\"Cosine Similarity:\")\n",
    "    for i in range(len(actual_speeches)):\n",
    "        for j in range(len(generated_speeches)):\n",
    "            print(f\"Speech Pair ({i+1}, {j+1}): {cosine_similarity[i, j]}\")\n",
    "\n",
    "    # Apply PCA to reduce dimensionality to 3D\n",
    "    pca = PCA(n_components=3)\n",
    "    pca_embeddings = pca.fit_transform(np.concatenate((actual_embeddings, generated_embeddings), axis=0))\n",
    "\n",
    "    # Separate the PCA embeddings back to actual and generated\n",
    "    actual_pca_embeddings = pca_embeddings[: len(actual_embeddings)]\n",
    "    generated_pca_embeddings = pca_embeddings[len(actual_embeddings) :]\n",
    "\n",
    "    # Visualize the embeddings in a 3D scatter plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(actual_pca_embeddings[:, 0], actual_pca_embeddings[:, 1], actual_pca_embeddings[:, 2], c='blue', label='Actual Speeches')\n",
    "    ax.scatter(generated_pca_embeddings[:, 0], generated_pca_embeddings[:, 1], generated_pca_embeddings[:, 2], c='red', label='Generated Speeches')\n",
    "    ax.set_xlabel('PCA Component 1')\n",
    "    ax.set_ylabel('PCA Component 2')\n",
    "    ax.set_zlabel('PCA Component 3')\n",
    "    ax.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TlSakPhKXUyy",
    "outputId": "90ea349d-af8b-41e2-9a82-2409d9a2ccbf"
   },
   "outputs": [],
   "source": [
    "def print_results(id):\n",
    "    print('Speaker id:' + str(id))\n",
    "    print('========== Rouge and Bleu Score ==========')\n",
    "    calculate_rouge_bleu_score(str(id))\n",
    "    print('========== Cosine Similarities and Embeddings ==========')\n",
    "    create_embeddings_and_calculate_cos_sim(str(id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BkL-x6aSXfii"
   },
   "outputs": [],
   "source": [
    "print_results(101112641)\n",
    "print_results(101109290)\n",
    "print_results(104118220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
